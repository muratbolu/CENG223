\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{amsmath}

\usepackage[hmargin=3cm,vmargin=6.0cm]{geometry}
%\topmargin=0cm
\topmargin=-2cm
\addtolength{\textheight}{6.5cm}
\addtolength{\textwidth}{2.0cm}
%\setlength{\leftmargin}{-5cm}
\setlength{\oddsidemargin}{0.0cm}
\setlength{\evensidemargin}{0.0cm}

%misc libraries goes here
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{mathabx}
\usepackage[symbol]{footmisc}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand\+{\mkern2mu}
\let\eps\varepsilon

\begin{document}

\section*{Student Information } 
%Write your full name and id number between the colon and newline
%Put one empty space character after colon and before newline
Full Name : Murat Bolu \\
Id Number : 2521300 \\

% Write your answers below the section tags
\section*{Answer 1}

A function $f: A \rightarrow B$ is surjective if and only if $\forall b \in B, \; \exists \+ a \in A$ such that $f(a) = b$. \\
A function $f: A \rightarrow B$ is injective if and only if $\forall a_1 \in A, \; \forall a_2 \in A$, $f(a_1) = f(a_2) \rightarrow a_1 = a_2$. \\
%The same statement can be expressed by its contrapositive: $\forall a_1 \in A, \; \forall a_2 \in A$, $a_1 \neq a_2 \rightarrow f(a_1) \neq f(a_2)$. \\
The set of nonnegative real numbers $\overline{\mathbb{R}}^+ = \{0\} \cup \mathbb{R}^+$.

\paragraph{a)} % For f_1
\begin{itemize}
\item $f_1$ is not surjective since $-1 \in \mathbb{R}$, and there does not exists an $a$ such that $f_1(a) = -1$, since $\forall x \in \mathbb{R}, \; x^2 \geq 0 > -1$.
\item $f_1$ is not injective since $f_1(2) = f_1(-2) = 4$, and $2 \neq -2$.
\end{itemize}

\paragraph{b)} % For f_2
\begin{itemize}
\item $f_2$ is not surjective since $-1 \in \mathbb{R}$, and there does not exists an $a$ such that $f_2(a) = -1$, since $\forall x \in \mathbb{R}, \; x^2 \geq 0 > -1$. \\
\\
\item $f_2$ is injective since $\forall a_1 \in \overline{\mathbb{R}}^+, \; \forall a_2 \in \overline{\mathbb{R}}^+$:
\begin{align*}
f_2(a_1) = f_2(a_2) &\rightarrow a_1 \+ ^2 = a_2 \+ ^2 \\
&\rightarrow a_1 \+ ^2 - a_2 \+ ^2 = 0 \\
&\rightarrow (a_1 - a_2)(a_1 + a_2) = 0
\end{align*}
\noindent
This means that either $a_1 - a_2 = 0 \rightarrow a_1 = a_2$ or $a_1 + a_2 = 0$.
If $a_1 + a_2 = 0$, $a_1 = a_2 = 0$ since $a_1 \in \{0\} \cup \mathbb{R}^+$ and $a_2 \in \{0\} \cup \mathbb{R}^+$.
I will prove this by contradiction.
Suppose that $a_1$ is not zero but a positive real number.
This would mean that $a_1 + a_2$ is strictly greater than $a_2$: $\; a_1 + a_2 > a_2$.
That would mean zero is strictly greater than $a_2$: $\; 0 > a_2$.
That is not possible since $a_2 \in \{0\} \cup \mathbb{R}^+$ and every value of $a_2$ is equal to or greater than zero.
This leads to a contradiction, therefore $a_1$ must be zero since $a_1 \in \{0\} \cup \mathbb{R}^+$.
Since $a_1 = 0$, $a_1 + a_2 = 0 \rightarrow 0 + a_2 = 0 \rightarrow a_2 = 0$.
Therefore, if $a_1 + a_2 = 0$, $a_1 = a_2$.
We have already shown that if $a_1 - a_2 = 0$, $a_1 = a_2$.
Therefore, $\forall a_1 \in \overline{\mathbb{R}}^+, \; \forall a_2 \in \overline{\mathbb{R}}^+, \; f_2(a_1) = f_2(a_2) \rightarrow a_1 = a_2$.
\end{itemize}

\newpage

\paragraph{c)}
\begin{itemize}
\item $f_3$ is surjective since $\forall b \in \overline{\mathbb{R}}^+, \; \exists \+ a \in \mathbb{R}$ such that $a = \sqrt{b}$ and $f_3(\sqrt{b}) = (\sqrt{b})^2 = \vert \+ b \+ \vert = b$ since $b \geq 0$ since $b \in \{0\} \cup \mathbb{R}^+$.
Therefore, $\forall b \in \overline{\mathbb{R}}^+, \; \exists \+ a = \sqrt{b} \in \mathbb{R}$ such that $f_3(a) = b$.
\item $f_3$ is not injective since $f_3(2) = f_3(-2) = 4$, and $2 \neq -2$.
\end{itemize}

\paragraph{d)}
\begin{itemize}
\item $f_4$ is surjective since $\forall b \in \overline{\mathbb{R}}^+, \; \exists \+ a \in \overline{\mathbb{R}}^+$ such that $a = \sqrt{b}$ and $f_4(\sqrt{b}) = (\sqrt{b})^2 = \vert \+ b \+ \vert = b$ since $b \geq 0$ since $b \in \{0\} \cup \mathbb{R}^+$.
Therefore, $\forall b \in \overline{\mathbb{R}}^+, \; \exists \+ a = \sqrt{b} \in \overline{\mathbb{R}}^+$ such that $f_4(a) = b$.
\item $f_4$ is injective since $\forall a_1 \in \overline{\mathbb{R}}^+, \; \forall a_2 \in \overline{\mathbb{R}}^+$:
\begin{align*}
f_4(a_1) = f_4(a_2) &\rightarrow a_1 \+ ^2 = a_2 \+ ^2 \\
&\rightarrow a_1 \+ ^2 - a_2 \+ ^2 = 0 \\
&\rightarrow (a_1 - a_2)(a_1 + a_2) = 0
\end{align*}
This means that either $a_1 - a_2 = 0 \rightarrow a_1 = a_2$ or $a_1 + a_2 = 0$.
If $a_1 + a_2 = 0$, $a_1 = a_2 = 0$ since $a_1 \in \{0\} \cup \mathbb{R}^+$ and $a_2 \in \{0\} \cup \mathbb{R}^+$.
The proof is similar to above.
\end{itemize}

\section*{Answer 2}
\paragraph{a)}
Since $f: A \subset \mathbb{Z} \subset \mathbb{R} \rightarrow \mathbb{R}$, we can take $n$ and $m$ to be $1$ and apply the definition of continuity.
\begin{gather*}
\forall \eps \in \mathbb{R}^+ \; \exists \+ \delta \in \mathbb{R}^+ \; \forall x \in A \; (\Vert x - x_0 \Vert < \delta \rightarrow \Vert f(x) - f(x_0) \Vert < \eps)
\end{gather*}
The Euclidean norm in $\mathbb{R}^n = \mathbb{R}$ simply becomes the absolute value of the number itself, since $\Vert \+ x \+ \Vert = \sqrt{\scriptstyle\sum_{i = 1}^{n} x_i \+ ^2} = \sqrt{\scriptstyle\sum_{i = 1}^{1}x_i \+ ^2} = \sqrt{x_1 \+ ^2} = \vert \+ x_1 \+ \vert$.
\begin{gather*}
\forall \eps \in \mathbb{R}^+ \; \exists \+ \delta \in \mathbb{R}^+ \; \forall x \in A \; (\vert \+ x - x_0 \+ \vert < \delta \rightarrow \vert \+ f(x) - f(x_0) \+ \vert < \eps)
\end{gather*}
I claim that for all $\eps$, taking $\delta < 1$ works, which would mean $\vert \+ x - x_0 \+ \vert$ must also be less than one.
\begin{gather*} %\forall \eps \in \mathbb{R}^+ \; 
\forall x \in A \; (\vert \+ x - x_0 \+ \vert < 1 \rightarrow \vert \+ f(x) - f(x_0) \+ \vert < \eps)
\end{gather*}
In that case, either $x = x_0$ or $x \neq x_0$.
\begin{itemize}
\item In the first case, $x = x_0 \rightarrow f(x) = f(x_0) \rightarrow f(x) - f (x_0) = 0$.
Additionally, $x = x_0 \rightarrow x - x_0 = 0$.
Since the both sides of the implication are true, the result is true.
%which would make the right hand side of the implication true since $\vert \+ f(x) - f(x_0) \+ \vert = \vert \+ 0 \+ \vert = 0 < \eps, \; \forall \eps \in \mathbb{R}^+$ and therefore the result true.
\item In the second case, $\vert \+ x - x_0 \+ \vert$ must take positive integer values like $\{1, 2, 3, \dotsc\}$ since $x, x_0 \in \mathbb{Z}$.
In that case $\vert \+ x - x_0 \+ \vert < 1$ is always false, and the result is vacuously true.
%In that case taking $\delta = \frac{1}{2}$ would work since the left hand side of the equation will always be false, and the result will always be true.
\end{itemize}
Therefore, $\delta < 1$ satisfies the definition of continuity for all $\eps$, $x$ and $x_0$.
Since we assumed nothing about $x_0$, the function $f$ is continuous for all $x_0$ in $A$.

\newpage

\paragraph{b)}
Since $f: \mathbb{R} \rightarrow \mathbb{Z} \subset \mathbb{R}$, we can take $n$ and $m$ to be $1$ and apply the definition of continuity.
\begin{gather*}
\forall \eps \in \mathbb{R}^+ \; \exists \+ \delta \in \mathbb{R}^+ \; \forall x \in \mathbb{R} \; (\Vert x - x_0 \Vert < \delta \rightarrow \Vert f(x) - f(x_0) \Vert < \eps)
\end{gather*}
Similarly, the Euclidean norm in $\mathbb{R}^n = \mathbb{R}$ simply becomes the absolute value of the number itself, since $\Vert \+ x \+ \Vert = \sqrt{\scriptstyle\sum_{i = 1}^{n} x_i \+ ^2} = \sqrt{\scriptstyle\sum_{i = 1}^{1}x_i \+ ^2} = \sqrt{x_1 \+ ^2} = \vert \+ x_1 \+ \vert$.
\begin{gather*}
\forall \eps \in \mathbb{R}^+ \; \exists \+ \delta \in \mathbb{R}^+ \; \forall x \in \mathbb{R} \; (\vert \+ x - x_0 \+ \vert < \delta \rightarrow \vert \+ f(x) - f(x_0) \+ \vert < \eps)
\end{gather*}
The question is to show that $f$ being a constant function is a necessary and sufficient condition for the function $f: \mathbb{R} \rightarrow \mathbb{Z}$ to be continuous (at every point).
This means that the truth of one implies the other.
\begin{itemize}
\item The first part is to show that $f$ being a constant function is a sufficient condition for the function $f: \mathbb{R} \rightarrow \mathbb{Z}$ to be continuous.
That means $f$ being a constant function implies $f: \mathbb{R} \rightarrow \mathbb{Z}$ is continuous.
Since $f$ is constant, $f(x) = f(x_0)$ for all $x \in \mathbb{R}$ and $x_0 \in \mathbb{R}$, which would imply $\vert \+ f(x) - f(x_0) \+ \vert = \vert \+ 0 \+ \vert = 0 < e$ for all $\eps \in \mathbb{R}^+$.
Since the right hand side of the implication is true for all $\eps$, $x$ and $x_0$, and it is independent of $\delta$, it is always true.
$\delta$ can be chosen arbitrarily.

\item The second part is to show that $f$ being a constant function is a necessary condition for the function $f: \mathbb{R} \rightarrow \mathbb{Z}$ to be continuous.
That means $f: \mathbb{R} \rightarrow \mathbb{Z}$ being continuous implies $f$ is a constant function.
The proof will involve Intermediate Value Theorem, which says that a continuous function $f$ whose domain contains the interval $[a, b]$ takes on all values between $f(a)$ and $f(b)$ in that interval.
I will pick two numbers and show that $f(a) = f(b)$ for all $a$ and $b$.
\begin{itemize}
\item If $a$ and $b$ are equal, $f(a) = f(b)$ trivially by the virtue of $f$ being a function.
\item If $a$ and $b$ are different, assume that $f(a) \neq f(b)$.
That would mean $f$ needs to take a non-integer value between $f(a)$ and $f(b)$, since there always exist (uncountably infinitely many) real numbers between any two different integers.
Since the codomain of $f$ is the set of integers, that is not possible, thus $f(a)$ cannot be different from $f(b)$.
\end{itemize}
Since we assumed nothing about $a$ and $b$, they can be chosen arbitrarily among all real numbers, showing that $f$ has the same value throughout its domain, i.e. $f$ is constant.

%Let $a$ be an arbitrary point on the domain of $f$, which is $\mathbb{R}$.
%We will assume nothing about this point, and show that $f(x) = f(a)$ for all $x$, which means any two points picked from the domain of $f$ is equal, meaning $f$ is constant.
%Since $f$ is continuous at its domain, we can write the definition of continuity for $a$.
%\begin{gather*}
%\forall \eps \in \mathbb{R}^+ \; \exists \+ \delta \in \mathbb{R}^+ \; \forall x \in \mathbb{R} \; (\vert \+ x - a \+ \vert < \delta \rightarrow \vert \+ f(x) - f(a) \+ \vert < \eps)
%\end{gather*}
%Since this premise is true and $\eps$ is existentially quantified, we can pick an arbitrarily small $\eps$.
%I will take $\eps$ to be less than one.
%In that case, $\vert \+ x - a \+ \vert < \delta$ implies $\vert \+ f(x) - f(a) \+ \vert < 1 \rightarrow \vert \+ f(x) - f(a) \+ \vert = 0$ since $f: \mathbb{R} \rightarrow \mathbb{Z}$ and $\vert \+ f(x) - f(a) \+ \vert$ can only take non-negative integer values like $\{0, 1, 2, \dotsc\}$.
%That would mean $f(x) - f(a) = 0 \rightarrow f(x) = f(a)$ for all $x$.
\end{itemize}

\newpage

\section*{Answer 3}
\paragraph{a)}
Proof by mathematical induction:
\begin{enumerate}
\item Basis: $X_2 = A_1 \times A_2$ is countable since $A_1 = \{a_{11}, a_{12}, \dotsc \}$ and $A_2 = \{a_{21}, a_{22}, \dotsc \}$ can be enumerated by the sum of $i$ and $j$ in indices of $a_{1i}$ and $a_{2j}$.
\begin{align*}
(a_{11}, a_{21}) && i + j = 2 \\
(a_{11}, a_{22}), (a_{12}, a_{21}) && i + j = 3 \\
(a_{11}, a_{23}), (a_{12}, a_{22}), (a_{13}, a_{21}) && i + j = 4 \\
\dotsc && \dotsc \\
(a_{11}, a_{2(n-1)}), (a_{12}, a_{2(n-2)}), \dotsc, (a_{1(n-2)}, a_{22}), (a_{1(n-1)}, a_{21}) && i + j = n\\
\dotsc && \dotsc \\
\end{align*}
\item Inductive Step: Assuming $X_k = A_1 \times A_2 \times \dotsc \times A_k$ is countable, I will show that $X_{k+1} = A_1 \times A_2 \times \dotsc \times A_k \times A_{k+1}$ is countable.
%Let $A_1 = \{a_{11}, a_{12}, \dotsc\}$, $A_2 = \{a_{21}, a_{22}, \dotsc\}$, $\dotsc$, $A_k = \{a_{k1}, a_{k2}, \dotsc\}$.
%Let $i_\xi$ be the indices where the elements are $a_{1i_\xi}, a_{2i_\xi}, \dotsc, a_{ki_\xi}$, the sum of indices are $\sum_{\xi = 1}^{k} = n$ and $\xi \in \{1, 2, \dotsc, k\}$.
%Then $X_k = \{(a_{11}, a_{21}, \dotsc), (a_{12}, a_{21}, \dotsc), \dotsc\}$ where the elements are grouped by the sum of their indices are:
%\begin{align*}
%(a_{11}, a_{21}, \dotsc, a_{k1}) && &\sum_{\xi = 1}^{k} i_\xi = k \\
%(a_{12}, a_{21}, \dotsc, a_{k1}), (a_{11}, a_{22}, \dotsc, a_{k1}), \dotsc, (a_{11}, a_{21}, \dotsc, a_{k2}) && &\sum_{\xi = 1}^{k} i_\xi = k + 1
%\end{align*}
\end{enumerate}
\paragraph{b)}
Let $S = X \times X \times \dotso$ be the set of infinite countable product of the set $X = \{0, 1\}$.
Then, every element of S can be represented by an infinite sequence of ones and zeros, since they will be in the form $(1, 0, 0, 1, \dotso)$.
I will use Cantor's Diagonal Argument to show that $S$ is uncountably infinite.
Assuming $S$ is countable, let $s_i \in S$ where $i \in \mathbb{N}$.
Then, let $s_\text{new}$ be the representation such that $i^{th}$ digit of $s_\text{new}$ is $0$ if $i^{th}$ digit of $s_i$ is $1$, and $1$ if $i^{th}$ digit of $s_i$ is $0$.
Since $s_\text{new}$ is different from every $s_i \in S$, it isn't in $S$.
Since it is not in enumeration, enumeration is not complete.
This contradicts the assumption that the enumeration was complete, i.e. $S$ is countable.
Thus, $S$ is uncountable.
\begin{align*}
s_1 &= 1011010\dotso \\
s_2 &= 0110101\dotso \\
s_3 &= 0001111\dotso \\
s_4 &= 1100001\dotso \\
& \vdots \\
s_\text{new} &= 0011\dotso
\end{align*}

\section*{Answer 4}
I will first show that for functions $f, g,$ and $h$, if $f \in O(g)$ and $g \in O(h)$, then $f \in O(h)$.
\begin{align*}
f \in O(g) &\leftrightarrow \exists \+ c_1 \; \exists \+ k_1 \; (\forall x \geq k_1 \; (\vert f(x) \vert \leq c_1 \cdot \vert g(x) \vert)) \\
g \in O(h) &\leftrightarrow \exists \+ c_2 \; \exists \+ k_2 \; (\forall x \geq k_2 \; (\vert g(x) \vert \leq c_2 \cdot \vert h(x) \vert)) \\
f \in O(h) &\leftrightarrow \exists \+ c_3 \; \exists \+ k_3 \; (\forall x \geq k_3 \; (\vert f(x) \vert \leq c_3 \cdot \vert h(x) \vert))
\end{align*}
For $x$ values bigger than both $k_1$ and $k_2$, both equations are satisfied.
We can multiply the second equation by $c_1$.
\begin{align*}
(f \in O(g)) \land (g \in O(h)) \leftrightarrow& \; \exists \+ c_1 \; \exists \+ k_1 \; \exists \+ c_2 \; \exists \+ k_2 \; \forall x \\
&(((x \geq k_1) \land (x \geq k_2)) \rightarrow (\vert f(x) \vert \leq c_1 \cdot \vert g(x) \vert \leq c_1 \cdot c_2 \cdot \vert h(x) \vert))
\end{align*}
Therefore, there exists a $c_3$ value such that $c_3 = c_1 \cdot c_2$ and there exists a $k_3$ value such that $k_3 = \text{max}\{k_1, k_2\}$ that makes $\vert f(x) \vert \leq c_3 \cdot \vert h(x) \vert$ for all $x$ values greater than $k_3$.
\begin{align*}
(f \in O(g)) \land (g \in O(h)) &\leftrightarrow \exists \+ c_3 \; \exists \+ k_3 \; (\forall x \geq k_3 \; (\vert f(x) \vert \leq c_3 \cdot \vert h(x) \vert)) \\
(f \in O(g)) \land (g \in O(h)) &\leftrightarrow f \in O(h)
\end{align*}
\paragraph{a)} % Compare your first and second functions
\begin{gather*}
O((n!)^2) \ni (5^n) \leftrightarrow \exists \+ c \; \exists \+ k \; (\forall x \geq k \; (\vert 5^x \vert \leq c \cdot \vert (x!)^2 \vert))
\end{gather*}
Let $c = \frac{5^5}{5!}$ and $k = 6$.
Since for $k \geq 6$ both of these functions are always positive, we can get rid of absolute value signs.
\begin{align*}
5^x &\leq 5^5 \cdot 5^{x-5} && \forall x \geq 6 \\
&\leq 5^5 \cdot (5 \cdot 5 \cdot \dotso \cdot 5) && \forall x \geq 6 \\
&\leq 5^5 \cdot (6 \cdot 7 \cdot \dotso \cdot x) && \forall x \geq 6 \\
&\leq 5^5 \cdot \tfrac{x!}{5!} && \forall x \geq 6 \\
&\leq \tfrac{5^5}{5!} \cdot x! \cdot x! && \forall x \geq 6 \\
&\leq \tfrac{5^5}{5!} \cdot (x!)^2 && \forall x \geq 6
\end{align*}
\paragraph{b)} % Compare your second and third functions
\begin{gather*}
O(5^n) \ni (2^n) \leftrightarrow \exists \+ c \; \exists \+ k \; (\forall x \geq k \; (\vert 2^x \vert \leq c \cdot \vert 5^x \vert))
\end{gather*}
Let $c = 1$ and $k = 1$.
Since for $k \geq 1$ both of these functions are always positive, we can get rid of absolute value signs.
\begin{align*}
2^x &\leq 2 \cdot 2 \cdot \dotso \cdot 2 && \forall x \geq 1 \\
&\leq 5 \cdot 5 \cdot \dotso \cdot 5 && \forall x \geq 1 \\
&\leq 5^x && \forall x \geq 1
\end{align*}
Before these four proofs I will have to prove that $\log_2{x} \leq \frac{x}{51}, \; \forall x \geq 500$, $\log_2{x} \leq x, \; \forall x \geq 1$, and $\log_2{x} \leq \sqrt{x}, \; \forall x \geq 16$.
I will show this by showing $\displaystyle\lim_{x \to \infty} \tfrac{\log_2{x}}{ax^b} = 0$ for all $a, b$ where $a > 0, b > 0$, which implies $\log_2{x} \in O(ax^b)$ for all $a, b$ where $a > 0, b > 0$.
\begin{align*}
\displaystyle\lim_{x \to \infty} \tfrac{\log_2{x}}{ax^b} &= \displaystyle\lim_{x \to \infty} \tfrac{\ln{x}}{\ln{2} \cdot ax^b}\\
&= \displaystyle\lim_{x \to \infty} \tfrac{1/x}{\ln{2} \cdot a \cdot b \cdot x^{b-1}} && \text{By L'HÃ´pital's rule, since $[\tfrac{0}{0}]$ indeterminacy} \\
&= \displaystyle\lim_{x \to \infty} \tfrac{1}{\ln{2} \cdot a \cdot b \cdot x^b} \\
&= 0 && \text{Due to $[\tfrac{1}{\infty}]$ form}
\end{align*}
\paragraph{c)}
\begin{gather*}
O(2^n) \ni (n^{51}+n^{49}) \leftrightarrow \exists \+ c \; \exists \+ k \; (\forall x \geq k \; (\vert n^{51}+n^{49} \vert \leq c \cdot \vert 2^x \vert))
\end{gather*}
Let $c = 2$ and $k = 500$.
Since for $k \geq 500$ both of these functions are always positive, we can get rid of absolute value signs.
\begin{align*}
x^{51}+x^{49} &\leq x^{51}+x^{51} && \forall x \geq 500 \\
&\leq 2 \cdot x^{51} && \forall x \geq 500 \\
&\leq 2 \cdot 2^{\log_2{(x^{51})}} && \forall x \geq 500 \\
&\leq 2 \cdot 2^{51 \cdot \log_2{x}} && \forall x \geq 500 \\
&\leq 2 \cdot 2^{51 \cdot \frac{x}{51}\footnotemark} && \forall x \geq 500 \\
&\leq 2 \cdot 2^{x} && \forall x \geq 500
\end{align*}
\footnotetext{Since $\log_2{x} \leq \frac{x}{51}, \; \forall x \geq 500$.}
\paragraph{d)}
\begin{gather*}
O(n^{51}+n^{49}) \ni (n^{50}) \leftrightarrow \exists \+ c \; \exists \+ k \; (\forall x \geq k \; (\vert n^{50} \vert \leq c \cdot \vert n^{51}+n^{49} \vert))
\end{gather*}
Let $c = 1$ and $k = 1$.
Since for $k \geq 1$ both of these functions are always positive, we can get rid of absolute value signs.
\begin{align*}
x^{50} &\leq x^{51} && \forall x \geq 1 \\
&\leq x^{51}+x^{49} && \forall x \geq 1
\end{align*}
For these two proofs I am assuming $\log{n}$ is of base $2$, however, proofs are similar for different bases.
\paragraph{e)}
\begin{gather*}
O(n^{50}) \ni (\sqrt{n} \cdot \log{n}) \leftrightarrow \exists \+ c \; \exists \+ k \; (\forall x \geq k \; (\vert \sqrt{n} \cdot \log{n} \vert \leq c \cdot \vert n^{50} \vert))
\end{gather*}
Let $c = 1$ and $k = 1$.
Since for $k \geq 1$ both of these functions are always positive, we can get rid of absolute value signs.
\begin{align*}
\sqrt{x} \cdot \log{x} &\leq \sqrt{x} \cdot x\footnotemark && \forall x \geq 1 \\
&\leq x^{\frac{1}{2}} \cdot x && \forall x \geq 1 \\
&\leq x^{\frac{3}{2}} && \forall x \geq 1 \\
&\leq x^{50} && \forall x \geq 1
\end{align*}
\footnotetext{Since $\log{x} \leq x, \; \forall x \geq 1$.}
\paragraph{f)}
\begin{gather*}
O(\sqrt{n} \cdot \log{n}) \ni (\log{n})^2 \leftrightarrow \exists \+ c \; \exists \+ k \; (\forall x \geq k \; (\vert (\log{n})^2 \vert \leq c \cdot \vert \sqrt{n} \cdot \log{n} \vert))
\end{gather*}
Let $c = 1$ and $k = 16$.
Since for $k \geq 16$ both of these functions are always positive, we can get rid of absolute value signs.
\begin{align*}
(\log{x})^2 &\leq (\log{x}) \cdot (\log{x}) && \forall x \geq 16 \\
&\leq \sqrt{x}\footnotemark \cdot \log{x} && \forall x \geq 16
\end{align*}
\footnotetext{Since $\log{x} \leq \sqrt{x}, \; \forall x \geq 16$.}

\section*{Answer 5}
\paragraph{a)}
\begin{align*}
\text{gdc}(94, 134) &= \text{gdc}(134, 94) \\
&= \text{gdc}(94, 134 \bmod 94) \\
&= \text{gdc}(94, 40) \\
&= \text{gdc}(40, 94 \bmod 40) \\
&= \text{gdc}(40, 14) \\
&= \text{gdc}(14, 40 \bmod 14) \\
&= \text{gdc}(14, 12) \\
&= \text{gdc}(12, 14 \bmod 12) \\
&= \text{gdc}(12, 2) \\
&= \text{gdc}(2, 12 \bmod 2) \\
&= \text{gdc}(2, 0) \\
&= 2
\end{align*}
\paragraph{b)}
We will have to show it both ways.
First, assume Goldbach's conjecture and reach to the conclusion given in the question.
Second, assume the conclusion given in the question is correct and reach Goldbach's conjecture.
\begin{enumerate}
\item Assuming Goldbach's conjecture, where $n = p_1 + p_2$, $n = 2k$, $k \in \{2, 3, 4, \dotso\}$, and $p_1$ and $p_2$ are primes.
Then, we can add $2$, a prime number, making the equation $n + 2 = p_1 + p_2 + 2$.
Since $n$ is even, $n + 2$ is even, therefore $n + 2 = 2l$, $l \in \{3, 4, 5, \dotso\}$.
This shows that every even integer greater than $5$ can be written as a sum of three primes.
Or, we can add $3$, a prime number, making the equation $n + 3 = p_1 + p_2 + 3$.
Since $n$ is even, $n + 3$ is odd, therefore $n + 3 = 2m + 1$, $m \in \{3, 4, 5, \dotso\}$.
Therefore, every odd integer greater than $5$ can be written as a sum of three primes.
Therefore, every integer greater than $5$ can be written as a sum of three primes.
\item Assuming that every integer greater than $5$ can be written as a sum of three primes, where $n = p_1 + p_2 + p_3$, $n \in \{6, 7, 8, \dotso\}$ and $p_1$, $p_2$ and $p_3$ are primes.
The only even prime is $2$, so if one of $p_i$'s are $2$, $n$ must be even, since the sum of an even number, an odd number and an odd number is an even number.
Without loss of generality, we can assume that $p_3 = 2$.
Then, we can subtract $2$, making the equation $n - 2 = p_1 + p_2$.
Since $n$ is even, $n - 2$ is even, therefore $n - 2 = 2k$, $k \in \{2, 3, 4, \dotso\}$.
If all three primes are odd, then $n$ must be odd, since the sum of three odd numbers is odd.
Additionally, since the smallest odd prime is $3$, n is at least $9$.
Since all $p_i$'s are odd, we can sum any two of them to get an even number.
Without loss of generality, we can choose $p_2$ and $p_3$.
Every number greater than 5 can be written as a sum of three primes, and since our primes are at least $3$ and $3$, every sum of $p_2$ and $p_3$ can be written as a sum of three primes.
Since the sum is even, one of the primes must be $2$, since only the sum of one even number and two odd numbers can make an even number, remembering the fact that $2$ is the only prime number.
Therefore, $n = p_1 + p_4 + p_5 + 2$.
We can subtract $3$, making the equation $n - 3 = p_1 + p_4 + p_5 - 1$.
\end{enumerate}

\end{document}